{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population <-> Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To hide the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd \n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('swiss_population_pickle.pkl', 'rb') as f:\n",
    "    population = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will check how many cities are considered large, where a large city has more than `POP_LIMIT_LARGE_CITY` number of inhabitants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 31 large cities in Switzerland\n"
     ]
    }
   ],
   "source": [
    "POP_LIMIT_LARGE_CITY = 24000\n",
    "large_cities = [city for city, pop in population.items() if pop > POP_LIMIT_LARGE_CITY]\n",
    "print(\"There are {} large cities in Switzerland\".format(len(large_cities)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following small function returns a set of possible names for a city, as they might be found in the stop dataset. For example, when given Zürich, it will return `[Zürich HB, Zürich Hbf, ...]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_city_names(city_orig_name):\n",
    "    stop_extensions = ['HB', 'Hbf', 'SBB', 'CFF']\n",
    "    return [\"{} {}\".format(city_orig_name, ext) for ext in stop_extensions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function goes through the given names of stops, and tries to find which stop matches to the provided cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_stop_names(cities, stop_names):\n",
    "    city_stop_names = []\n",
    "    \n",
    "    for city in cities:\n",
    "        found = False\n",
    "        if city in stop_names.values:\n",
    "            found = True\n",
    "            city_stop_names.append(city)\n",
    "\n",
    "        if not found:\n",
    "            for alt_name in alt_city_names(city):\n",
    "                if alt_name in stop_names.values:\n",
    "                    found = True\n",
    "                    city_stop_names.append(alt_name)\n",
    "                    break\n",
    "                    \n",
    "        if not found:\n",
    "            if city == \"Fribourg\":\n",
    "                city_stop_names.append(\"Fribourg/Freiburg\")\n",
    "            if city == \"Rapperswil-Jona\":\n",
    "                city_stop_names.append(\"Rapperswil\")\n",
    "\n",
    "    return(city_stop_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('stop_data_complete.csv', sep=',', encoding='latin-1')\n",
    "del df['Unnamed: 0']\n",
    "\n",
    "large_city_stop_names = real_stop_names(large_cities, df['stop_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have the following:\n",
      "Basel SBB : (47.547649085507601, 7.5895514262328696), etc.\n"
     ]
    }
   ],
   "source": [
    "large_cities_centers = {}\n",
    "for stop in large_city_stop_names:\n",
    "    matching_lines = df.loc[df['stop_name'] == stop]\n",
    "    # Multiple lines can match for one stop. \n",
    "    # This is usually because each platform counts as a stop in bigger stations\n",
    "    # We arbitrarily take the first, this makes very little difference.\n",
    "    stop_line = matching_lines.iloc[0]\n",
    "    large_cities_centers[stop] = (stop_line['stop_lat'], stop_line['stop_lon'])\n",
    "    \n",
    "print(\"We now have the following:\")\n",
    "print(\"{} : {}, etc.\".format('Basel SBB', large_cities_centers['Basel SBB']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Downloading geopy-1.11.0-py2.py3-none-any.whl (66kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 1.6MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: geopy\n",
      "Successfully installed geopy-1.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import vincenty as geo_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the [GeoPy](http://geopy.readthedocs.io/en/1.10.0/) library and the vincenty algorithm, we can now use the geo_dist function to calculate distances between two stops. Here is an example for Lausanne and Zürich:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between Lausanne and Zürich as the crow flies:\n",
      "174.17 km\n"
     ]
    }
   ],
   "source": [
    "print(\"Distance between Lausanne and Zürich as the crow flies:\")\n",
    "print('{:.2f} km'.format(geo_dist(large_cities_centers['Lausanne'], large_cities_centers['Zürich HB']).km))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this function we now construct a function that returns the set of stops (train or bus, not yet filtered) that is within XX km of a given city's train station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stops_in_range(df, city_stop_name, city_stop_coords, max_dist):\n",
    "    in_range = []\n",
    "    for index, row in df.iterrows():\n",
    "        if not row['stop_name'] == city_stop_name:\n",
    "            if geo_dist(city_stop_coords, (row['stop_lat'], row['stop_lon'])).km < max_dist:\n",
    "                in_range.append(row['stop_name'])\n",
    "    return set(in_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for every large city, we find all stops that are closer than 5km from its train station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all stops for:\n",
      "\n",
      "Dübendorf .... done\n",
      "Uster .... done\n",
      "Winterthur .... done\n",
      "Dietikon .... done\n",
      "Zürich HB .... done\n",
      "Biel/Bienne .... done\n",
      "Bern .... done\n",
      "Köniz .... done\n",
      "Thun .... done\n",
      "Luzern .... done\n",
      "Zug .... done\n",
      "Fribourg/Freiburg .... done\n",
      "Basel SBB .... done\n",
      "Schaffhausen .... done\n",
      "St. Gallen .... done\n",
      "Rapperswil .... done\n",
      "Chur .... done\n",
      "Frauenfeld .... done\n",
      "Lugano .... done\n",
      "Yverdon-les-Bains .... done\n",
      "Lausanne .... done\n",
      "Montreux .... done\n",
      "Sion .... done\n",
      "La Chaux-de-Fonds .... done\n",
      "Neuchâtel .... done\n",
      "Genève .... done\n",
      "Vernier .... done\n"
     ]
    }
   ],
   "source": [
    "stops_to_close = {}\n",
    "print(\"Processing all stops for:\")\n",
    "print()\n",
    "for city, coords in large_cities_centers.items():\n",
    "    print(\"{}\".format(city), end='')\n",
    "    stops_to_close[city] = stops_in_range(df, city, coords, 5)\n",
    "    print(\" .... done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the example for Lausanne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lausanne, Rovéréaz', 'Pully, Trois-Chasseurs', 'Cery-Fleur-de-Lys', 'St-Sulpice VD, Pâqueret', 'Epalinges, Croisettes', 'Lausanne, St-Etienne', 'Lausanne, Valmont', 'Lausanne-Chauderon', 'Prilly-Malley', 'Pully-Nord', 'Ecublens VD, Champagne', 'Ecublens VD, EPFL (bus)', 'Renens VD', 'Ecublens VD, Blévallaire', 'Lausanne, Sallaz', 'Union-Prilly', 'Prilly-Chasseur', 'Lausanne, Le Foyer', 'Pully', 'La Conversion', 'Lausanne, Bourdonnette', 'Jouxtens-Mézery', 'Lausanne-Flon', 'Montblesson, Centenaire', 'Ecublens VD, Dorigny', 'Lutry', 'Ecublens VD, EPFL Piccard', 'Le Lussex', 'Montétan'}\n"
     ]
    }
   ],
   "source": [
    "print(stops_to_close['Lausanne'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we save the result to file, so it can be used else where:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stops_too_close.pkl', 'wb') as f:\n",
    "    pickle.dump(stops_to_close, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how to open and use the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lausanne, Rovéréaz', 'Pully, Trois-Chasseurs', 'Cery-Fleur-de-Lys', 'St-Sulpice VD, Pâqueret', 'Epalinges, Croisettes', 'Lausanne, St-Etienne', 'Lausanne, Valmont', 'Lausanne-Chauderon', 'Prilly-Malley', 'Pully-Nord', 'Ecublens VD, Champagne', 'Ecublens VD, EPFL (bus)', 'Renens VD', 'Ecublens VD, Blévallaire', 'Lausanne, Sallaz', 'Union-Prilly', 'Prilly-Chasseur', 'Lausanne, Le Foyer', 'Pully', 'La Conversion', 'Lausanne, Bourdonnette', 'Jouxtens-Mézery', 'Lausanne-Flon', 'Montblesson, Centenaire', 'Ecublens VD, Dorigny', 'Lutry', 'Ecublens VD, EPFL Piccard', 'Le Lussex', 'Montétan'}\n"
     ]
    }
   ],
   "source": [
    "with open('stops_too_close.pkl', 'rb') as f:\n",
    "    stops_too_close = pickle.load(f)\n",
    "    print(stops_too_close['Lausanne'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding population data for all stops\n",
    "\n",
    "We will now take the list of stops, take only the train stops (`type = Train`), and try to find population data for the associated city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('stop_with_type.csv', sep=',', encoding='latin-1')\n",
    "del df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_only_train = df[df['type'] == 'Train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_cantons = ['SH', 'BS', 'TG', 'AG', 'JU', 'BL', 'ZH', 'AI', 'VD', 'NE', 'SO', 'LU', 'ZG', 'SG', 'AR', 'FR', 'BE', 'NW', 'GE', 'SZ', 'GL', 'GR', 'VS', 'OW', 'UR', 'TI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function may look not very clean, but this is mostly for optimization reasons.\n",
    "\n",
    "If we find the population for the current stop it goes directly into the map, and the stop name is saved to make sure we don't run it again, and if we don't find it at all, it goes into the `not_found` list.\n",
    "\n",
    "In order we try to match the following:\n",
    "1. The full stop name directly (~500 occurences)\n",
    "2. The stop name without HB, CFF, SBB, Hbf attached (~20 occurences)\n",
    "3. Stop names with the canton in the name (~130 occurences)\n",
    "4. Stop names for stops in between two villages such as Puidoux-Chexbres (~30 occurences)\n",
    "5. Stop names in two languages such as Fribourg/Freiburg (~few)\n",
    "6. Stop names of multiple words where the first word is a city (~30 occurences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_keys = population.keys()\n",
    "pop_city_match = {}\n",
    "treated_stops = []\n",
    "not_found = []\n",
    "\n",
    "for index, row in df_only_train.iterrows():\n",
    "\n",
    "    stop_name = row['stop']\n",
    "    if stop_name not in treated_stops:\n",
    "        if stop_name in population_keys:\n",
    "            treated_stops.append(stop_name)\n",
    "            pop_city_match[stop_name] = population[stop_name]\n",
    "        else:\n",
    "#             not_found.append(stop_name)\n",
    "            if stop_name[-2:] == 'HB':\n",
    "                if stop_name[:-3] in population_keys:\n",
    "                    treated_stops.append(stop_name)\n",
    "                    pop_city_match[stop_name] = population[stop_name[:-3]]\n",
    "            elif stop_name[-3:] in ['SBB', 'CFF', 'Hbf']:\n",
    "                if stop_name[:-4] in population_keys:\n",
    "                    treated_stops.append(stop_name)\n",
    "                    pop_city_match[stop_name] = population[stop_name[:-4]]\n",
    "            \n",
    "            # Check for stops with canton name: 'Buchs ZH' is 'Buchs (ZH)' in the data\n",
    "            elif stop_name[-2:] in swiss_cantons:\n",
    "                canton_format = '{} ({})'.format(stop_name[:-3], stop_name[-2:])\n",
    "                if canton_format in population.keys():\n",
    "                    treated_stops.append(stop_name)\n",
    "                    pop_city_match[stop_name] = population[canton_format]\n",
    "            \n",
    "            # Now check for names with a dash in them: Puidoux-Chexbres\n",
    "            elif len(stop_name.split('-')) > 1:\n",
    "                name_parts = stop_name.split('-')\n",
    "                population_combined = 0\n",
    "                if name_parts[0] not in treated_stops and name_parts[0] in population_keys:\n",
    "                    population_combined += population[name_parts[0]]\n",
    "                if name_parts[1] not in treated_stops and name_parts[1] in population_keys:\n",
    "                    population_combined += population[name_parts[1]]\n",
    "                \n",
    "                # Observation: there are few stops that have more than 1 dash in the name (Morges-st-Jean)\n",
    "                # but most of these are not very relevant because of how small they are.\n",
    "                \n",
    "                # If one of the parts of the name matched (or both parts),\n",
    "                # then add the total population to the table.\n",
    "                # Example: Puidoux-Chexbres\n",
    "                if population_combined != 0:\n",
    "                    treated_stops.append(stop_name)\n",
    "                    pop_city_match[stop_name] = population_combined\n",
    "                else:\n",
    "                    not_found.append(stop_name)\n",
    "             \n",
    "            elif len(stop_name.split('/')) > 1:\n",
    "                name_parts = stop_name.split('/')\n",
    "                if name_parts[0] in population.keys() and name_parts[0] not in treated_stops:\n",
    "                    treated_stops.append(stop_name)\n",
    "                    pop_city_match[stop_name] = population[name_parts[0]]   \n",
    "                elif name_parts[1] in population.keys() and name_parts[1] not in treated_stops:\n",
    "                    treated_stops.append(stop_name)\n",
    "                    pop_city_match[stop_name] = population[name_parts[1]]\n",
    "                else:\n",
    "                    not_found.append(stop_name)\n",
    "            \n",
    "            elif len(stop_name.split(' ')) > 1:\n",
    "                first_part = stop_name.split(' ')[0]\n",
    "                if first_part not in treated_stops and first_part in population_keys:\n",
    "                    treated_stops.append(stop_name)\n",
    "                    pop_city_match[stop_name] = population[first_part]\n",
    "                else:\n",
    "                    not_found.append(stop_name)\n",
    "                \n",
    "            else:\n",
    "                not_found.append(stop_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stops processed, population data found for:\n",
      "720 stops/cities\n",
      "Not found for:\n",
      "1135 stops/cities\n"
     ]
    }
   ],
   "source": [
    "print(\"Stops processed, population data found for:\")\n",
    "print(\"{} stops/cities\".format(len(treated_stops)))\n",
    "print(\"Not found for:\")\n",
    "print(\"{} stops/cities\".format(len(not_found)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The other stops....\n",
    "\n",
    "The stops that we didn't find population data for are a mix of various options such as:\n",
    "- Cities outside of Switzerland\n",
    "- Cities that are not the same name as a commune\n",
    "- Cities that are not cities, but merely train stops on the outskirts of some other commune\n",
    "- Mountain train stops\n",
    "- etc\n",
    "\n",
    "We will now set the population data for all these cities to `-1` to indicate they have no data, and then the model can decide how to handle that problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stop in not_found:\n",
    "    pop_city_match[stop] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pop_to_row(row):\n",
    "    if row['type'] == 'Train':\n",
    "        try:\n",
    "            return pop_city_match[row['stop']]\n",
    "        except:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.apply(add_pop_to_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['population'] = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('stops_with_population.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
