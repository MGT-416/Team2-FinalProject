{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First data cleaning - CFF Railway Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file you can find the first part of the data cleaning I've done for the MidTerm Project. I create new .csv file with only the relevant information on trains for routes, trips and stops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import the data for the routes, trips and stops from the .txt file.\n",
    "# In the repository stop_times.txt and trips.txt have to be extracted for the ZIP files because of the files' size. \n",
    "data_routes = pd.read_csv('routes.txt', sep=\",\")\n",
    "data_trips = pd.read_csv('trips.txt', sep=\",\")\n",
    "data_stop = pd.read_csv('stop_times.txt', sep=\",\")\n",
    "\n",
    "routes = dict()\n",
    "trips = dict()\n",
    "stop_id = list()\n",
    "stop = dict()\n",
    "valid_type = ['Eurocity','Extrazug','ICE','Intercity','InterRegio','Railjet','RegioExpress','Regionalzug','S-Bahn','Schnellzug','TGV']\n",
    "\n",
    "# To consider only the routes relative to trains\n",
    "for i in range(len(data_routes)):\n",
    "    if((data_routes['route_desc'][i] in valid_type) == True):\n",
    "            routes[data_routes['route_id'][i]] = data_routes['route_desc'][i]\n",
    "            \n",
    "# To consider only trips corresponding to train routes\n",
    "for i in range(len(data_trips)):\n",
    "    if ((data_trips['route_id'][i] in list(routes)) == True):\n",
    "            trips[data_trips['trip_id'][i]] = data_trips['trip_short_name'][i]\n",
    "            \n",
    "# To consider only stops associated to valid trips\n",
    "for i in range(len(data_stop)):\n",
    "    if((data_stop['trip_id'][i] in list(trips)) == True):\n",
    "            if((data_stop['stop_id'][i] in stop_id) == False):\n",
    "                stop_id.append(data_stop['stop_id'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creation of DataFrame to stock the data\n",
    "data_stop_relevant = pd.DataFrame(stop_id)\n",
    "\n",
    "data_trips_relevant = pd.DataFrame([list(trips.keys()),list(trips.values())])\n",
    "data_trips_relevant = data_trips_relevant.transpose()\n",
    "\n",
    "data_routes_relevant = pd.DataFrame([list(routes.keys()),list(routes.values())])\n",
    "data_routes_relevant = data_routes_relevant.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creation of the csv file relevant for further analysis\n",
    "data_stop_relevant.to_csv('stop_id_relevant.csv',sep=',')\n",
    "data_trips_relevant.to_csv('trips_relevant.csv',sep=',')\n",
    "data_routes_relevant.to_csv('routes_relevant.csv',sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
